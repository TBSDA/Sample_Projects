{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interior-support",
   "metadata": {},
   "source": [
    "# Stroke Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-northern",
   "metadata": {},
   "source": [
    "Final stroke prediction model based on the research in the Stroke_Prediction_Model_Searching_2 on the healthcare-dataset-stroke-data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-topic",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "floral-muslim",
   "metadata": {},
   "source": [
    "Acknowledgements\n",
    "(Confidential Source) - Use only for educational purposes\n",
    "If you use this dataset in your research, please credit the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thorough-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imPipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "manufactured-drinking",
   "metadata": {},
   "source": [
    "Cleansing and preprocessing data. \n",
    "The details about data exploration can be found in the Stroke_Prediction_Data_Exploration notebook.\n",
    "The details about building pipelines in the Stroke_Prediction_Cleansing_and_Preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    ''' Simple class for selecting given attributes form given data frame. \n",
    "        Inspired by https://sklearn-features.readthedocs.io/en/latest/_modules/transformers.html '''\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "class MyLabelBinarizer(LabelBinarizer):\n",
    "    ''' Customized LabelBinarizer to make it work with pipeline which require two arguments.\n",
    "        Returs the same as LabelBinarizer. '''\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(LabelBinarizer, self).fit_transform(X)\n",
    "\n",
    "class CustomLimitedImputer(BaseEstimator, TransformerMixin):\n",
    "    ''' Simple customized imputer to change the following:\n",
    "        smoking_status to \"never smoked\" if age < 10 and smoking_status = \"Unknown\"\n",
    "        work_type to \"children\" if age < 17 and swork_type = \"Never_worked\" '''\n",
    "    def __init__(self, attribute_names):\n",
    "        assert all(attr in ['smoking_status', 'work_type'] for attr in attribute_names), 'Only smoking_status and work_type are supported'\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for attr in self.attribute_names:\n",
    "            if attr == 'smoking_status':\n",
    "                X.loc[(X.age < 10) & (X.smoking_status == 'Unknown'), 'smoking_status'] = 'never smoked'\n",
    "            elif attr == 'work_type':\n",
    "                X.loc[(X.age < 17) & (X.work_type == 'Never_worked'), 'work_type'] = 'children'\n",
    "        X.drop(['age'], axis=1, inplace=True)\n",
    "        return X.values\n",
    "\n",
    "# pipelines\n",
    "cat_yn_pipeline = Pipeline([\n",
    "        (\"select_bin\", DataFrameSelector(['ever_married'])),\n",
    "        (\"bin_encoder\", MyLabelBinarizer()),\n",
    "    ])\n",
    "\n",
    "cat_oh_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector(['smoking_status', 'work_type', 'age'])), # age is used as a CustomLimitedImputer parameter\n",
    "        (\"imputer\", CustomLimitedImputer(['smoking_status', 'work_type'])),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector(['age', 'avg_glucose_level'])),\n",
    "        (\"scale\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# final preprocessing pipeline\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('cat_yn_pipeline', cat_yn_pipeline),\n",
    "        ('cat_oh_pipeline', cat_oh_pipeline),\n",
    "        ('num_pipeline', num_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intense-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/healthcare-dataset-stroke-data.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liked-google",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51676</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31112</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60182</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18234</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44873</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19723</th>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37544</th>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44679</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "id                                                                             \n",
       "9046     Male  67.0             0              1          Yes        Private   \n",
       "51676  Female  61.0             0              0          Yes  Self-employed   \n",
       "31112    Male  80.0             0              1          Yes        Private   \n",
       "60182  Female  49.0             0              0          Yes        Private   \n",
       "1665   Female  79.0             1              0          Yes  Self-employed   \n",
       "...       ...   ...           ...            ...          ...            ...   \n",
       "18234  Female  80.0             1              0          Yes        Private   \n",
       "44873  Female  81.0             0              0          Yes  Self-employed   \n",
       "19723  Female  35.0             0              0          Yes  Self-employed   \n",
       "37544    Male  51.0             0              0          Yes        Private   \n",
       "44679  Female  44.0             0              0          Yes       Govt_job   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "id                                                                      \n",
       "9046           Urban             228.69  36.6  formerly smoked       1  \n",
       "51676          Rural             202.21   NaN     never smoked       1  \n",
       "31112          Rural             105.92  32.5     never smoked       1  \n",
       "60182          Urban             171.23  34.4           smokes       1  \n",
       "1665           Rural             174.12  24.0     never smoked       1  \n",
       "...              ...                ...   ...              ...     ...  \n",
       "18234          Urban              83.75   NaN     never smoked       0  \n",
       "44873          Urban             125.20  40.0     never smoked       0  \n",
       "19723          Rural              82.99  30.6     never smoked       0  \n",
       "37544          Rural             166.29  25.6  formerly smoked       0  \n",
       "44679          Urban              85.28  26.2          Unknown       0  \n",
       "\n",
       "[5110 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-camcorder",
   "metadata": {},
   "source": [
    "Split data into three datasets: train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upset-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(data[data.columns[:-1]], data.stroke, test_size=0.2, random_state=24, stratify=data.stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "commercial-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=24, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liberal-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(X_train)\n",
    "X_val = preprocess_pipeline.transform(X_val)\n",
    "X_test = preprocess_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-communist",
   "metadata": {},
   "source": [
    "Quick look on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacterial-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3270, 12)\n",
      "(818, 12)\n",
      "(1022, 12)\n",
      "(3270,)\n",
      "(818,)\n",
      "(1022,)\n",
      "0    3111\n",
      "1     159\n",
      "Name: stroke, dtype: int64\n",
      "0    778\n",
      "1     40\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-potato",
   "metadata": {},
   "source": [
    "Data are imbalanced. There are many more no-stoke individuals than stroke ones so let's perform the resampling. More details can be found in \"Stroke_Prediction_Model_Searching_v2\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "random-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3111\n",
       "1     159\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-detector",
   "metadata": {},
   "source": [
    "Pipeline for oversampling and undersampling. The values and algorithms have been chosen based on the research covered in the \"Stroke_Prediction_Model_Searching_v2\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oriental-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_v = 0.5\n",
    "undersample_v = 0.7\n",
    "oversample_tq = ADASYN(sampling_strategy=oversample_v, random_state=24)\n",
    "undersample_tq = RandomUnderSampler(sampling_strategy=undersample_v, random_state=24)\n",
    "resample_pipeline = imPipeline([('oversampling', oversample_tq), ('undersampling', undersample_tq)])\n",
    "X_train_ou, y_train_ou = resample_pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "authorized-integer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2195\n",
       "1    1537\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ou.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-header",
   "metadata": {},
   "source": [
    "Before model training, the metric needs to be selected.\n",
    "The choice is F2 score because is better for the models where positive class and preventing false negatives are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ambient-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-armor",
   "metadata": {},
   "source": [
    "Now let's create benchmark for score using DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrapped-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 1\n",
    "dc = DummyClassifier(strategy='constant', constant=1, random_state=24) \n",
    "\n",
    "# randomly sampled but in stratified manner\n",
    "# dc = DummyClassifier(strategy='c', random_state=24)\n",
    "\n",
    "dc.fit(X_train, y_train)\n",
    "dc_y_pred = dc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "welsh-magazine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2035330261136713"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_train, dc_y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-bonus",
   "metadata": {},
   "source": [
    "In case the model predicts only 1 the f2_score is 0.2035.\n",
    "<br>\n",
    "In case the model predicts randomly in balanced way the f2_score is 0.0624."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-sharing",
   "metadata": {},
   "source": [
    "To make sure the datasets are split equally (in terms of classes) during cross validation let's use the Stratified Fold. Furthermore the splits will be produced differently in a couple repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extra-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-parker",
   "metadata": {},
   "source": [
    "Function for evaluating the cross validation of train dataset and validation dataset prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "corrected-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores(model, X, y, cv):\n",
    "    ''' Calculate the cross validation scores based on f2_scores metric and then the mean of them.\n",
    "        Parameters:\n",
    "            model    - model to be used for fitting data and predictions\n",
    "            X        - X train dataset\n",
    "            y        - y train dataset\n",
    "            cv       - Cross validation splitting strategy\n",
    "        Returns:\n",
    "            The mean value of calculated f2 scores. '''\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=f2_scorer)\n",
    "    return scores.mean()\n",
    "\n",
    "def get_val_pred_score(model, X, y, X_v, y_v):\n",
    "    ''' Calculate the f2_score of prediction for given model. \n",
    "        Parameters:\n",
    "            model    - model to be used for fitting data and predictions\n",
    "            X        - X train dataset\n",
    "            y        - y train dataset\n",
    "            X_v      - X validation dataset (works for test dataset as well)\n",
    "            y_v      - y validation dataset (works for test dataset as well)\n",
    "        Result:\n",
    "            f2_score of predicted values. '''\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_v)\n",
    "    return fbeta_score(y_v, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-surrey",
   "metadata": {},
   "source": [
    "#### Now let's create the models. The two best performing based on the \"Stroke_Prediction_Model_Searching_v2\" notebook, are:\n",
    "SGDClassifier      - the best one from linear clissifiers\n",
    "AdaBoostClassifier - the best one from tree based classifiers\n",
    "\n",
    "Val_score   Algorithm(hyperparameters)\n",
    "0.4381      SGDClassifier(alpha=0.0004, penalty='elasticnet', l1_ratio=0.05, random_state=24)\n",
    "\n",
    "0.4103      AdaBoostClassifier(base_estimator=ExtraTreeClassifier(max_depth=2, min_samples_leaf=10, random_state=24),\n",
    "                             learning_rate=0.05, n_estimators=900, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-basement",
   "metadata": {},
   "source": [
    "Training the SGDClassifier model. More details in \"Stroke_Prediction_Model_Searching_v2\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mighty-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(alpha=0.0004, penalty='elasticnet', l1_ratio=0.05, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-absolute",
   "metadata": {},
   "source": [
    "Check the cross validated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faced-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773184552660715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_scores(sgd_clf, X_train_ou, y_train_ou, splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-development",
   "metadata": {},
   "source": [
    "Check the results for validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "parallel-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43814432989690727"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_pred_score(sgd_clf, X_train_ou, y_train_ou, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-thickness",
   "metadata": {},
   "source": [
    "Verify the model on the previously separated test data which have not been seen and not used for evaluating by the model previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "solar-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0004, l1_ratio=0.05, penalty='elasticnet',\n",
       "              random_state=24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train_ou, y_train_ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prompt-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "following-explorer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34934497816593885"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-darkness",
   "metadata": {},
   "source": [
    "The confusion matrix for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ongoing-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[746, 226],\n",
       "       [ 18,  32]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-malpractice",
   "metadata": {},
   "source": [
    "#### The results are:\n",
    "    380% and 1239% better than the benchmark* for train dataset\n",
    "    215% and 702% better than the benchmark* for verification dataset\n",
    "    172% and 560% better than the benchmark* for test dataset\n",
    "\n",
    "#### For the test dataset which was unseen during the whole research:\n",
    "    The 64% (32 of 50) strokes have been predicted correctly. \n",
    "    The 23% (226 of 972) non-strokes where considered wrongly as strokes. \n",
    "    \n",
    "________________________________\n",
    "**benchmark for train dataset 0.2035 (only 1) and 0.0624 (randomly balanced)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-portsmouth",
   "metadata": {},
   "source": [
    "Training the AdaBoostClassifier model. More details in \"Stroke_Prediction_Model_Searching_v2\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alive-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_clf = AdaBoostClassifier(base_estimator=ExtraTreeClassifier(max_depth=2, min_samples_leaf=10, random_state=24),\n",
    "                             learning_rate=0.05, n_estimators=900, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-right",
   "metadata": {},
   "source": [
    "Check the cross validated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "portuguese-filename",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111404412281389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_scores(ab_clf, X_train_ou, y_train_ou, splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-classroom",
   "metadata": {},
   "source": [
    "Check the results for validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pressed-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41033434650455936"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_pred_score(ab_clf, X_train_ou, y_train_ou, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-nirvana",
   "metadata": {},
   "source": [
    "Verify the model on the previously separated test data which have not been seen and not used for evaluating by the model previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "persistent-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=ExtraTreeClassifier(max_depth=2,\n",
       "                                                      min_samples_leaf=10,\n",
       "                                                      random_state=24),\n",
       "                   learning_rate=0.05, n_estimators=900, random_state=24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_clf.fit(X_train_ou, y_train_ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pediatric-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ab_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "brilliant-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35175879396984927"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-webcam",
   "metadata": {},
   "source": [
    "The confusion matrix for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tough-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[802, 170],\n",
       "       [ 22,  28]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-biotechnology",
   "metadata": {},
   "source": [
    "### The results are:\n",
    "    399% and 1300% better than the benchmark* for train dataset\n",
    "    202% and 658% better than the benchmark* for verification dataset++\n",
    "    173% and 564% better than the benchmark* for test dataset\n",
    "\n",
    "#### For the test dataset which was unseen during the whole research:\n",
    "    The 56% (28 of 50) strokes have been predicted correctly. \n",
    "    The 17% (226 of 972) non-strokes where considered wrongly as strokes.\n",
    "\n",
    "________________________________\n",
    "**benchmark for train dataset 0.2035 (only 1) and 0.0624 (randomly balanced)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-inspection",
   "metadata": {},
   "source": [
    "### Steps description:\n",
    "    1. In the Stroke_Prediction_Data_Exploration notebook the following were performed:\n",
    "            - Data overview\n",
    "            - Features and samples exploratory analysis\n",
    "            - Data evaluation\n",
    "    \n",
    "    2. In the Stroke_Prediction_Cleansing_and_Preprocessing notebook the pipelines were build to perform all actions based            on findings from the previous steps (notebook).\n",
    "    \n",
    "    3. In the Stroke_Prediction_Model_Searching and Stroke_Prediction_Model_Searching_2 notebooks all research can be found.\n",
    "       Checked classification algorithms:\n",
    "           - LogisticRegression\n",
    "           - LinearDiscriminantAnalysis\n",
    "           - GaussianNB\n",
    "           - KNeighborsClassifier\n",
    "           - SVC\n",
    "           - LinearSVC\n",
    "           - SGDClassifier\n",
    "           - DecisionTreeClassifier\n",
    "           - RandomForestClassifier\n",
    "           - ExtraTreesClassifier\n",
    "           - BaggingClassifier\n",
    "           - GradientBoostingClassifier\n",
    "           - AdaBoostClassifier\n",
    "           - HistGradientBoostingClassifier\n",
    "       Checked outlier/anomaly detection algorithms:\n",
    "           - OneClassSVM\n",
    "           - IsolationForest\n",
    "           - LocalOutlierFactor\n",
    "       Checked resampling:\n",
    "           - SMOTE\n",
    "           - BorderlineSMOTE\n",
    "           - SVMSMOTE\n",
    "           - SMOTENC\n",
    "           - ADASYN\n",
    "           - RandomUnderSampler\n",
    "           - CondensedNearestNeighbour\n",
    "           - TomekLinks\n",
    "           - EditedNearestNeighbours\n",
    "           - NeighbourhoodCleaningRule\n",
    "       Checked metrics:\n",
    "           - recall\n",
    "           - f2-score\n",
    "       Hyperparameters tuning techniques:\n",
    "           - RandomizedSearchCV\n",
    "           - GridSearchCV\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-dairy",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "    From all above the best performing were:\n",
    "      Models:\n",
    "        - SGDClassifier      - the best one from linear clissifiers\n",
    "        - AdaBoostClassifier - the best one from tree based classifiers\n",
    "        \n",
    "      Sampling techniques:\n",
    "        - ADASYN             - for oversampling\n",
    "        - RandomUnderSampler - for undersampling\n",
    "        \n",
    "    Used metric was f2-score which favoritize positive class and preventing false negatives to appear.\n",
    "    \n",
    "    Achieved f2-scores for unseen test dataset are:\n",
    "        - SGDClassifier:      0.3493\n",
    "        - AdaBoostClassifier: 0.3518\n",
    "    \n",
    "    Despite that the benchmark (DummyClassifier) was beaten in both cases, the results are far away from the desired ones.\n",
    "    Models have pretty high numbers of False Negative and False Positive. \n",
    "    It is out of the question to put such models as a replacement of medical supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-burning",
   "metadata": {},
   "source": [
    "#### Ideas for improvement:\n",
    "    1. Collect more samples especially for stroke class. Could be the problem cannot be solved due to lack of the positive  samples.\n",
    "    2. Reduce the feature number to simplify the classification decision making.\n",
    "    3. Research neural networks models.\n",
    "    4. Do the research on stroke medical papers to understand problem better.\n",
    "    5. Ask better questions during features and samples exploratory analysis.\n",
    "    6. Research more algorithms combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-circuit",
   "metadata": {},
   "source": [
    "#### Lessons learned:\n",
    "    1. Small imbalanced datasets may have strong tendency for overfitting. \n",
    "    2. Combining oversampling with undersampling can be beneficial. \n",
    "    3. Trees based algorithms are highly adaptive what can lead to overfitting.\n",
    "    4. Asking \"what can go wrong\" is a good approach in the initial phase. \n",
    "    5. Cross validation does not replace the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-motel",
   "metadata": {},
   "source": [
    "#### Final words:\n",
    "    The results are not on the desired level. That kind of models cannot be use as a replacement of medical expertise.\n",
    "    There is still some potential in the research but let's go further to work on other projects and come to that problem in future smarter and with more experience. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "social-hampton",
   "metadata": {},
   "source": [
    "# ATH finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-retention",
   "metadata": {},
   "source": [
    "Script to find new ATH in the WIG20, MWIG40 and SWIG80 companies."
   ]
  },
  {
   "cell_type": "raw",
   "id": "conventional-rebate",
   "metadata": {},
   "source": [
    "1. Get the tickers\n",
    "2. Gather the data\n",
    "3. Create the combined data with close (here the ATH is taken only from close price due to the purpose of this script - my strategy)\n",
    "4. Create the ATH list based on historical data (to file to skip additional request)\n",
    "5. Check last session to check potential new ATH (the assumption is the script is run every weekday) \n",
    "6. If new ATH(s) update the ATH list\n",
    "7. Enjoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aggregate-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yahoofinancials import YahooFinancials\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-vacuum",
   "metadata": {},
   "source": [
    "Get the tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "copyrighted-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wig_tickers(wig='wig20'):\n",
    "    ''' Get WIG components list. Only the wig20, mwig40 and swig80 are supported. '''\n",
    "    parsed_content = parse_wig_comps_data(wig=wig)\n",
    "    tickers = [ticker.get_text()[1:]+'.WA' for ticker in parsed_content]\n",
    "    return tickers\n",
    "\n",
    "def parse_wig_comps_data(wig):\n",
    "    ''' Parse data from https://strefainwestorow.pl/notowania/gpw/{wig}/komponenty '''\n",
    "    sublink = get_wig_sublink(wig)\n",
    "    source = requests.get(f'https://strefainwestorow.pl/notowania/gpw/{sublink}/komponenty').text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    table_w_symbols = soup.find_all('a', class_=\"instrument-symbol\")\n",
    "    return table_w_symbols\n",
    "\n",
    "def get_wig_sublink(wig):\n",
    "    if wig == 'wig20':\n",
    "        sublink = 'wig20-wig20'\n",
    "    elif wig == 'mwig40':\n",
    "        sublink = 'mwig40-mwig40'\n",
    "    elif wig == 'swig80':\n",
    "        sublink = 'swig80-swig80'\n",
    "    return sublink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liberal-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_wigs_tickers = get_wig_tickers('wig20')+get_wig_tickers('mwig40')+get_wig_tickers('swig80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "designing-american",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALE.WA', 'ACP.WA', 'CCC.WA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_wigs_tickers[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-jurisdiction",
   "metadata": {},
   "source": [
    "Gather the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rural-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start_date, end_date, tickers, interval):\n",
    "    yahoo_financials = YahooFinancials(tickers)\n",
    "    stats = yahoo_financials.get_historical_price_data(start_date, end_date, time_interval=interval)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bound-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1971-01-01'\n",
    "end_date = '2022-04-27'\n",
    "interval = 'daily'\n",
    "data = get_data(start_date, end_date, three_wigs_tickers, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sorted-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': 1602572400,\n",
       "  'high': 80.0,\n",
       "  'low': 71.08000183105469,\n",
       "  'open': 72.0,\n",
       "  'close': 80.0,\n",
       "  'volume': 18452974,\n",
       "  'adjclose': 80.0,\n",
       "  'formatted_date': '2020-10-13'},\n",
       " {'date': 1602658800,\n",
       "  'high': 90.30000305175781,\n",
       "  'low': 71.25,\n",
       "  'open': 84.0,\n",
       "  'close': 75.95999908447266,\n",
       "  'volume': 16731591,\n",
       "  'adjclose': 75.95999908447266,\n",
       "  'formatted_date': '2020-10-14'},\n",
       " {'date': 1602745200,\n",
       "  'high': 80.0,\n",
       "  'low': 71.5199966430664,\n",
       "  'open': 76.0,\n",
       "  'close': 79.22000122070312,\n",
       "  'volume': 6235974,\n",
       "  'adjclose': 79.22000122070312,\n",
       "  'formatted_date': '2020-10-15'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[three_wigs_tickers[0]]['prices'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-break",
   "metadata": {},
   "source": [
    "Create the combined data with close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "velvet-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_df(dist_data):\n",
    "    df_f = pd.DataFrame()\n",
    "    for ticker, hist_data in dist_data.items():\n",
    "        if 'prices' in hist_data.keys(): \n",
    "            df = pd.DataFrame(hist_data['prices'], columns=['close', 'formatted_date'])\n",
    "            df.set_index('formatted_date', inplace=True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.rename(columns={'close': f'{ticker}'}, inplace=True)\n",
    "            df_f = pd.concat([df_f, df], axis=1)\n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demographic-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df = get_close_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suburban-champagne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALE.WA</th>\n",
       "      <th>ACP.WA</th>\n",
       "      <th>CCC.WA</th>\n",
       "      <th>CDR.WA</th>\n",
       "      <th>CPS.WA</th>\n",
       "      <th>DNP.WA</th>\n",
       "      <th>JSW.WA</th>\n",
       "      <th>KGH.WA</th>\n",
       "      <th>LTS.WA</th>\n",
       "      <th>LPP.WA</th>\n",
       "      <th>...</th>\n",
       "      <th>TOA.WA</th>\n",
       "      <th>TRK.WA</th>\n",
       "      <th>UNT.WA</th>\n",
       "      <th>VRC.WA</th>\n",
       "      <th>VGO.WA</th>\n",
       "      <th>VOX.WA</th>\n",
       "      <th>VRG.WA</th>\n",
       "      <th>WWL.WA</th>\n",
       "      <th>WLT.WA</th>\n",
       "      <th>ZEP.WA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formatted_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.323006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.848099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.700001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.415743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.323006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.012699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.346441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>69.619820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.803799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>72.088608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.970901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.227637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.779305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.443001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.376142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-20</th>\n",
       "      <td>27.905001</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>51.720001</td>\n",
       "      <td>137.440002</td>\n",
       "      <td>26.580000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>68.900002</td>\n",
       "      <td>168.100006</td>\n",
       "      <td>72.260002</td>\n",
       "      <td>11240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1.836</td>\n",
       "      <td>47.799999</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>686.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>3.740000</td>\n",
       "      <td>471.0</td>\n",
       "      <td>7.41</td>\n",
       "      <td>17.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-21</th>\n",
       "      <td>28.045000</td>\n",
       "      <td>78.150002</td>\n",
       "      <td>55.080002</td>\n",
       "      <td>128.639999</td>\n",
       "      <td>26.040001</td>\n",
       "      <td>318.899994</td>\n",
       "      <td>69.019997</td>\n",
       "      <td>161.699997</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.26</td>\n",
       "      <td>1.840</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>44.799999</td>\n",
       "      <td>696.0</td>\n",
       "      <td>41.200001</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>470.0</td>\n",
       "      <td>7.42</td>\n",
       "      <td>17.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-22</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>53.020000</td>\n",
       "      <td>127.599998</td>\n",
       "      <td>25.820000</td>\n",
       "      <td>316.500000</td>\n",
       "      <td>64.339996</td>\n",
       "      <td>150.750000</td>\n",
       "      <td>69.739998</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.756</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>678.0</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>468.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>17.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>27.055000</td>\n",
       "      <td>77.949997</td>\n",
       "      <td>52.599998</td>\n",
       "      <td>130.720001</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>315.600006</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>140.600006</td>\n",
       "      <td>68.220001</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.05</td>\n",
       "      <td>1.682</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>676.0</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>468.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>16.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>24.615000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>127.959999</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>314.799988</td>\n",
       "      <td>65.220001</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.01</td>\n",
       "      <td>1.710</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>45.299999</td>\n",
       "      <td>684.0</td>\n",
       "      <td>40.099998</td>\n",
       "      <td>3.740000</td>\n",
       "      <td>462.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5784 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALE.WA     ACP.WA     CCC.WA      CDR.WA     CPS.WA  \\\n",
       "formatted_date                                                           \n",
       "2000-01-03            NaN  73.323006        NaN   38.848099        NaN   \n",
       "2000-01-04            NaN  73.323006        NaN   38.012699        NaN   \n",
       "2000-01-05            NaN  69.619820        NaN   37.803799        NaN   \n",
       "2000-01-06            NaN  72.088608        NaN   37.970901        NaN   \n",
       "2000-01-07            NaN  76.779305        NaN   43.443001        NaN   \n",
       "...                   ...        ...        ...         ...        ...   \n",
       "2022-04-20      27.905001  79.449997  51.720001  137.440002  26.580000   \n",
       "2022-04-21      28.045000  78.150002  55.080002  128.639999  26.040001   \n",
       "2022-04-22      27.000000  76.900002  53.020000  127.599998  25.820000   \n",
       "2022-04-25      27.055000  77.949997  52.599998  130.720001  25.799999   \n",
       "2022-04-26      24.615000  75.000000  50.700001  127.959999  25.799999   \n",
       "\n",
       "                    DNP.WA     JSW.WA      KGH.WA     LTS.WA   LPP.WA  ...  \\\n",
       "formatted_date                                                         ...   \n",
       "2000-01-03             NaN        NaN   26.700001        NaN      NaN  ...   \n",
       "2000-01-04             NaN        NaN   25.400000        NaN      NaN  ...   \n",
       "2000-01-05             NaN        NaN   25.299999        NaN      NaN  ...   \n",
       "2000-01-06             NaN        NaN   25.000000        NaN      NaN  ...   \n",
       "2000-01-07             NaN        NaN   27.900000        NaN      NaN  ...   \n",
       "...                    ...        ...         ...        ...      ...  ...   \n",
       "2022-04-20      327.000000  68.900002  168.100006  72.260002  11240.0  ...   \n",
       "2022-04-21      318.899994  69.019997  161.699997  70.000000  10400.0  ...   \n",
       "2022-04-22      316.500000  64.339996  150.750000  69.739998  10100.0  ...   \n",
       "2022-04-25      315.600006  63.860001  140.600006  68.220001   9990.0  ...   \n",
       "2022-04-26      314.799988  65.220001  138.600006  67.580002   9920.0  ...   \n",
       "\n",
       "                TOA.WA  TRK.WA     UNT.WA     VRC.WA  VGO.WA     VOX.WA  \\\n",
       "formatted_date                                                            \n",
       "2000-01-03         NaN     NaN        NaN        NaN     NaN        NaN   \n",
       "2000-01-04         NaN     NaN        NaN        NaN     NaN        NaN   \n",
       "2000-01-05         NaN     NaN        NaN        NaN     NaN        NaN   \n",
       "2000-01-06         NaN     NaN        NaN        NaN     NaN        NaN   \n",
       "2000-01-07         NaN     NaN        NaN        NaN     NaN        NaN   \n",
       "...                ...     ...        ...        ...     ...        ...   \n",
       "2022-04-20        6.25   1.836  47.799999  44.599998   686.0  41.299999   \n",
       "2022-04-21        6.26   1.840  46.799999  44.799999   696.0  41.200001   \n",
       "2022-04-22        6.30   1.756  47.000000  44.599998   678.0  40.500000   \n",
       "2022-04-25        6.05   1.682  48.000000  44.700001   676.0  40.500000   \n",
       "2022-04-26        6.01   1.710  46.500000  45.299999   684.0  40.099998   \n",
       "\n",
       "                  VRG.WA  WWL.WA  WLT.WA     ZEP.WA  \n",
       "formatted_date                                       \n",
       "2000-01-03      1.415743     NaN     NaN        NaN  \n",
       "2000-01-04      1.346441     NaN     NaN        NaN  \n",
       "2000-01-05           NaN     NaN     NaN        NaN  \n",
       "2000-01-06      1.227637     NaN     NaN        NaN  \n",
       "2000-01-07      1.376142     NaN     NaN        NaN  \n",
       "...                  ...     ...     ...        ...  \n",
       "2022-04-20      3.740000   471.0    7.41  17.799999  \n",
       "2022-04-21      3.850000   470.0    7.42  17.760000  \n",
       "2022-04-22      3.920000   468.0    7.50  17.340000  \n",
       "2022-04-25      3.830000   468.0    7.25  16.200001  \n",
       "2022-04-26      3.740000   462.0    7.10  16.000000  \n",
       "\n",
       "[5784 rows x 140 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-writing",
   "metadata": {},
   "source": [
    "For WIG there are quotes since 2000 on yahoo so it is needed to define the ATHs for companies with longer history than 2000-present. Let's take it from Strategies_Simulations/ATH.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "median-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "aths_for_older = {\n",
    "    'ACP.WA': 70.00,\n",
    "    'CDR.WA': 125.5,\n",
    "    'KGH.WA': 9.95,\n",
    "    'MBK.WA': 121.3,\n",
    "    'OPL.WA': 13.8,\n",
    "    'PEO.WA': 33.15,\n",
    "    'PKN.WA': 18.09,\n",
    "    'BDX.WA': 36.87,\n",
    "    'CMR.WA': 56,\n",
    "    'BHW.WA': 29.7,\n",
    "    'ING.WA': 26.94,\n",
    "    'KTY.WA': 35,\n",
    "    'MIL.WA': 9.93,\n",
    "    'AGO.WA': 42.77,\n",
    "    'AMC.WA': 52.2,\n",
    "    'BRS.WA': 0.28,\n",
    "    'BOS.WA': 74.53,\n",
    "    'ECH.WA': 0.28,\n",
    "    'FTE.WA': 12.56,\n",
    "    'RFK.WA': 13.55,\n",
    "    'SNK.WA': 3.79,\n",
    "    'STX.WA': 37.09,\n",
    "    'VRG.WA': 7.41}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-yugoslavia",
   "metadata": {},
   "source": [
    "Create the ATH list based on historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lovely-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "ath_ser = close_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "traditional-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALE.WA      94.639999\n",
       "ACP.WA     176.765228\n",
       "CCC.WA     309.000000\n",
       "CDR.WA     460.799988\n",
       "CPS.WA      37.860001\n",
       "             ...     \n",
       "VOX.WA      55.599998\n",
       "VRG.WA      16.790915\n",
       "WWL.WA    1459.000000\n",
       "WLT.WA      18.320000\n",
       "ZEP.WA      33.500000\n",
       "Length: 140, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ath_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-ranking",
   "metadata": {},
   "source": [
    "If any value from aths_for_older is greater than the one in ath_df for particular company it needs to be overrited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ath_by_dict(ser_in, ath_dict):\n",
    "    ser = ser_in.copy()\n",
    "    mask = ser.loc[ath_dict.keys()] > list(ath_dict.values())\n",
    "    index_to_replace = list(mask[mask == False].index)\n",
    "    values_to_update = [ath_dict[k] for k in index_to_replace]\n",
    "    ser.loc[index_to_replace] = values_to_update\n",
    "    return ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "featured-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "ath_ser = update_ath_by_dict(ath_ser, aths_for_older)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informational-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALE.WA      94.639999\n",
       "ACP.WA     176.765228\n",
       "CCC.WA     309.000000\n",
       "CDR.WA     460.799988\n",
       "CPS.WA      37.860001\n",
       "             ...     \n",
       "VOX.WA      55.599998\n",
       "VRG.WA      16.790915\n",
       "WWL.WA    1459.000000\n",
       "WLT.WA      18.320000\n",
       "ZEP.WA      33.500000\n",
       "Length: 140, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ath_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-portable",
   "metadata": {},
   "source": [
    "Add columns names and save to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efficient-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ath_data(series, file_path):\n",
    "    series.index.name = 'Ticker'\n",
    "    series.name = 'ATH'\n",
    "    series.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "unlikely-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ath_data(ath_ser, 'ATH_Data/ATH_WIG20_40_80.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-raise",
   "metadata": {},
   "source": [
    "Let's save also a tickers list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "rocky-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ATH_Data/WIG_tickers.txt\", \"w\") as output:\n",
    "#     output.write('\\n'.join(str(ticker) for ticker in three_wigs_tickers))\n",
    "    output.write('\\n'.join(three_wigs_tickers)) # simpler way - all elements are already strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-finnish",
   "metadata": {},
   "source": [
    "Read ATH data to skip gathering all data every time. That is a starting point for finding new potential ATH each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bound-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_data(file_path):\n",
    "    return pd.read_csv(file_path, index_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "round-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_saved_csv(path):\n",
    "    files = os.listdir(path)\n",
    "    files_paths = [os.path.join(path, basename) for basename in files]\n",
    "    return get_last_csv_path(files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "postal-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_csv_path(paths):\n",
    "    last_file = max(paths, key=os.path.getctime)\n",
    "    if last_file[-4:] == '.csv':\n",
    "        return last_file\n",
    "    else:\n",
    "        paths.remove(last_file)\n",
    "        return get_last_csv_path(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "specified-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ath_df = last_saved_csv('ATH_Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "national-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ath_df = read_csv_data(last_ath_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjusted-nickname",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALE.WA</th>\n",
       "      <td>94.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACP.WA</th>\n",
       "      <td>176.765228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCC.WA</th>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDR.WA</th>\n",
       "      <td>460.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPS.WA</th>\n",
       "      <td>37.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOX.WA</th>\n",
       "      <td>55.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRG.WA</th>\n",
       "      <td>16.790915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WWL.WA</th>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WLT.WA</th>\n",
       "      <td>18.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEP.WA</th>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ATH\n",
       "Ticker             \n",
       "ALE.WA    94.639999\n",
       "ACP.WA   176.765228\n",
       "CCC.WA   309.000000\n",
       "CDR.WA   460.799988\n",
       "CPS.WA    37.860001\n",
       "...             ...\n",
       "VOX.WA    55.599998\n",
       "VRG.WA    16.790915\n",
       "WWL.WA  1459.000000\n",
       "WLT.WA    18.320000\n",
       "ZEP.WA    33.500000\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ath_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-throw",
   "metadata": {},
   "source": [
    "Get tickers if there was no changes in indexes skip next two bloks. Otherwise skip third one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cultural-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_wigs_tickers = get_wig_tickers('wig20')+get_wig_tickers('mwig40')+get_wig_tickers('swig80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ATH_Data/WIG_tickers.txt\", \"w\") as output:\n",
    "    output.write('\\n'.join(three_wigs_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passing-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ATH_Data/WIG_tickers.txt\", \"r\") as file:\n",
    "    three_wigs_tickers = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lasting-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALE.WA', 'ACP.WA', 'CCC.WA']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_wigs_tickers[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-disco",
   "metadata": {},
   "source": [
    "Get data from today. Make sure the market is already closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rolled-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_prices_dict(tickers):\n",
    "    yahoo_financials = YahooFinancials(tickers)\n",
    "    return yahoo_financials.get_current_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defined-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_price_dict = get_current_prices_dict(three_wigs_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extensive-lunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(today_price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-referral",
   "metadata": {},
   "source": [
    "Compare with ATH data frame and show new ATH (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "local-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_ATHs(cur_ath_df, new_prices_dict):\n",
    "    mask = cur_ath_df.loc[new_prices_dict.keys(), 'ATH'] < list(new_prices_dict.values())\n",
    "    return list(cur_ath_df.loc[new_prices_dict.keys()][mask].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "optional-donor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is new ATH for: []'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ath = get_new_ATHs(ath_df, today_price_dict)\n",
    "f'There is new ATH for: {new_ath}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-plant",
   "metadata": {},
   "source": [
    "If any new ATH - update and save new ath csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "persistent-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ath_df_by_dict(df_in, ath_dict):\n",
    "    df = df_in.copy()\n",
    "    mask = df.loc[ath_dict.keys(), 'ATH'] < list(ath_dict.values())\n",
    "    index_to_replace = list(mask[mask].index)\n",
    "    values_to_update = [ath_dict[k] for k in index_to_replace]\n",
    "    df.loc[index_to_replace] = values_to_update\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "genetic-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_save(cur_ath_df, new_prices_dict, file_path):\n",
    "    df = update_ath_df_by_dict(cur_ath_df, new_prices_dict)\n",
    "    df.to_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "accredited-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no need to save updated ATH csv because of none new ATH.\n"
     ]
    }
   ],
   "source": [
    "if new_ath: \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    new_ATH_df = update_and_save(ath_df, today_price_dict, f'ATH_Data/ATH_WIG20_40_80_{today}.csv')\n",
    "else:\n",
    "    print('There is no need to save updated ATH csv because of none new ATH.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

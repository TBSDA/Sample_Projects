{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "timely-office",
   "metadata": {},
   "source": [
    "# TA Signal Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-venture",
   "metadata": {},
   "source": [
    "The combined script for TA signals. At the moment ATH, x-year max and price-ma crossing are covered. All signals, like maxima and ATHs, are calculated based only on close prices. What can be found as not fully correct, but it is done on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "unique-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yahoofinancials import YahooFinancials\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "rocky-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalFinder:\n",
    "    ''' The combined script for TA signals. At the moment ATH, x-year max and price-ma crossing are covered.\n",
    "        The supported indexes are wig20, mwig40 and swig80. That will be allowed to use combinations with '+' separator\n",
    "        e.g. 'wig20+mwig40'.\n",
    "        At the moment only wig20+mwig40+swig80 was fully tested. '''\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        self.file_name_part = index.replace('+', '_')\n",
    "        self.tickers = []\n",
    "        self.today_price_dict = {}\n",
    "        self.today_ma_dict = {}\n",
    "        self.new_ath = []\n",
    "        self.new_max = []\n",
    "        self.interval = 'daily'\n",
    "        self.aths_for_older = {}\n",
    "        self.actual_ma = 0\n",
    "\n",
    "    def get_new_ath_df(self, save=False):\n",
    "        ''' Get new ath data frame for the components of provided index.\n",
    "            Start day is statically set to the first date of data occurrence.\n",
    "            End day is today, but yahoo return historical data up to last session.\n",
    "            Interval is always 1D. '''\n",
    "        if not self.tickers:\n",
    "            self.tickers = self.get_tickers_list()\n",
    "        start_date = '1971-01-01' # for wig there are data since 2000 anyway\n",
    "        end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        data = self._get_historical_data(start_date, end_date)\n",
    "        close_df = self._get_close_df(data)\n",
    "        ath_ser = close_df.max()\n",
    "        self.__set_old_aths()\n",
    "        ath_ser = self._update_ath_ser_by_dict(ath_ser, self.aths_for_older)\n",
    "        ath_df = ath_ser.to_frame()\n",
    "        if save:\n",
    "            self.__save_initial_ath_df(ath_df)\n",
    "        return ath_df\n",
    "\n",
    "    def get_tickers_list(self):\n",
    "        ''' Get the ticker list. Currently only wig20, mwig40 and swig80 are supported. '''\n",
    "        if self.tickers:\n",
    "            return self.tickers\n",
    "        else:\n",
    "            index_list = self._get_index_list()\n",
    "            for index in index_list:\n",
    "                self.tickers += self._get_wig_tickers(index)\n",
    "            return self.tickers\n",
    "\n",
    "    def _get_index_list(self):\n",
    "        index_list = self.index.split('+')\n",
    "        return index_list\n",
    "\n",
    "    def _get_wig_tickers(self, wig):\n",
    "        ''' Get WIG components list. Only the wig20, mwig40 and swig80 are supported.\n",
    "            Returns a list of tickers'''\n",
    "        parsed_content = self._parse_wig_comps_data(wig=wig)\n",
    "        tickers = [ticker.get_text()[1:] + '.WA' for ticker in parsed_content]\n",
    "        return tickers\n",
    "\n",
    "    def _parse_wig_comps_data(self, wig):\n",
    "        ''' Parse data from https://strefainwestorow.pl/notowania/gpw/{wig}/komponenty\n",
    "            Returns the pre-processed table with the tickers.'''\n",
    "        sublink = self._get_wig_sublink(wig)\n",
    "        source = requests.get(f'https://strefainwestorow.pl/notowania/gpw/{sublink}/komponenty').text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        table_w_symbols = soup.find_all('a', class_=\"instrument-symbol\")\n",
    "        return table_w_symbols\n",
    "\n",
    "    def _get_wig_sublink(self, wig):\n",
    "        if wig == 'wig20':\n",
    "            sublink = 'wig20-wig20'\n",
    "        elif wig == 'mwig40':\n",
    "            sublink = 'mwig40-mwig40'\n",
    "        elif wig == 'swig80':\n",
    "            sublink = 'swig80-swig80'\n",
    "        return sublink\n",
    "\n",
    "    def _get_historical_data(self, start_date, end_date):\n",
    "        yahoo_financials = YahooFinancials(self.tickers)\n",
    "        stats = yahoo_financials.get_historical_price_data(start_date, end_date, time_interval=self.interval)\n",
    "        return stats\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_close_df(dist_data):\n",
    "        ''' Process the historical price data fetched from Yahoo.\n",
    "            Returns data frame with close prices of all tickers. '''\n",
    "        df_f = pd.DataFrame()\n",
    "        for ticker, hist_data in dist_data.items():\n",
    "            if 'prices' in hist_data.keys():\n",
    "                df = pd.DataFrame(hist_data['prices'], columns=['close', 'formatted_date'])\n",
    "                df.set_index('formatted_date', inplace=True)\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df.rename(columns={'close': f'{ticker}'}, inplace=True)\n",
    "                df_f = pd.concat([df_f, df], axis=1)\n",
    "        return df_f\n",
    "\n",
    "    def __set_old_aths(self):\n",
    "        ''' Manually assigned aths for current (2022Q2) WIG20, mWIG40 and sWIG80 components.\n",
    "            Every change of the indexes components the list need to be updated.\n",
    "            Dict has to contain only keys which are present in index components. '''\n",
    "        aths_for_older = {\n",
    "            'ACP.WA': 70.00,\n",
    "            'CDR.WA': 125.5,\n",
    "            'KGH.WA': 9.95,\n",
    "            'MBK.WA': 121.3,\n",
    "            'OPL.WA': 13.8,\n",
    "            'PEO.WA': 33.15,\n",
    "            'PKN.WA': 18.09,\n",
    "            'BDX.WA': 36.87,\n",
    "            'CMR.WA': 56,\n",
    "            'BHW.WA': 29.7,\n",
    "            'ING.WA': 26.94,\n",
    "            'KTY.WA': 35,\n",
    "            'MIL.WA': 9.93,\n",
    "            'AGO.WA': 42.77,\n",
    "            'AMC.WA': 52.2,\n",
    "            'BRS.WA': 0.28,\n",
    "            'BOS.WA': 74.53,\n",
    "            'ECH.WA': 0.28,\n",
    "            'FTE.WA': 12.56,\n",
    "            'RFK.WA': 13.55,\n",
    "            'SNK.WA': 3.79,\n",
    "            'STX.WA': 37.09,\n",
    "            'VRG.WA': 7.41\n",
    "        }\n",
    "        self.aths_for_older = {k: aths_for_older[k] for k in self.tickers if k in aths_for_older}\n",
    "\n",
    "    @staticmethod\n",
    "    def _update_ath_ser_by_dict(ser_in, ath_dict):\n",
    "        ''' Update ath series based on the new prices stored in dictionary.\n",
    "            Returns new series. '''\n",
    "        ser = ser_in.copy()\n",
    "        print(ser)\n",
    "        mask = ser.loc[ath_dict.keys()] > list(ath_dict.values())\n",
    "        index_to_replace = list(mask[mask == False].index)\n",
    "        values_to_update = [ath_dict[k] for k in index_to_replace]\n",
    "        ser.loc[index_to_replace] = values_to_update\n",
    "        return ser\n",
    "\n",
    "    def __save_initial_ath_df(self, df):\n",
    "        ''' Save initial ATH data frame. '''\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        df.index.name = 'Ticker'\n",
    "        df.rename(columns={0: \"ATH\"}, inplace=True)\n",
    "        df.to_csv(f'ATH_Data/ATH_{self.file_name_part}_{today}.csv')\n",
    "\n",
    "    def get_tickers_list_from_file(self):\n",
    "        ''' Can be use to set tickers list if you are sure there was no changes in components list. '''\n",
    "        with open(f\"Tickers/{self.file_name_part}_tickers.txt\", \"r\") as file:\n",
    "            self.tickers = file.read().splitlines()\n",
    "        return self.tickers\n",
    "\n",
    "    def save_tickers_list(self):\n",
    "        ''' Save tickers list to file if the they were fetched.\n",
    "            The files are stored in Tickers directory. '''\n",
    "        if self.tickers:\n",
    "            with open(f\"Tickers/{self.file_name_part}_tickers.txt\", \"w\") as tickers:\n",
    "                tickers.write('\\n'.join(self.tickers))\n",
    "        else:\n",
    "            print('There is no tickers in tickers list')\n",
    "\n",
    "    def _check_components_validity(self):\n",
    "        ''' To check if there were changes in indexes which indicate the ATH data frame update. '''\n",
    "        if self.tickers:\n",
    "            return self._compare_lists(self._read_tickers_list(), self.tickers)\n",
    "        else:\n",
    "            self.get_tickers_list()\n",
    "            return self._compare_lists(self._read_tickers_list(), self.tickers)\n",
    "\n",
    "    def _read_tickers_list(self):\n",
    "        ''' Return the tickers list from file located in Tickers directory\n",
    "            without setting the initialized ticker variable. '''\n",
    "        try:\n",
    "            with open(f\"Tickers/{self.file_name_part}_tickers.txt\", \"r\") as file:\n",
    "                tickers_file = file.read().splitlines()\n",
    "            return tickers_file\n",
    "        except FileNotFoundError:\n",
    "            print('There is no such file in Tickers directory. Please save the ticker list using save_tickers_list.')\n",
    "            sys.tracebacklimit=0\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _compare_lists(list1, list2):\n",
    "        return list1 == list2\n",
    "\n",
    "    def get_comp_ath_list(self):\n",
    "        ''' Get component/s with new ATH/s. Before running this function the tickers list\n",
    "         should be set and compered with previous one.\n",
    "         The return is a list of tickers. '''\n",
    "        cur_ath_df = self._read_csv_data('ath')\n",
    "        if not self.today_price_dict:\n",
    "            self._get_current_prices_dict()\n",
    "        mask = cur_ath_df.loc[self.today_price_dict.keys(), 'ATH'] < list(self.today_price_dict.values())\n",
    "        self.new_ath = list(cur_ath_df.loc[self.today_price_dict.keys()][mask].index)\n",
    "        return self.new_ath\n",
    "\n",
    "    def _read_csv_data(self, signal):\n",
    "        ''' The supported signals so far are 'ath', 'ma', 'x-years'\n",
    "            The path is the directory to search.\n",
    "            The file_path is a file path of the latest csv file.\n",
    "            Returns the data frame of file_path. '''\n",
    "        try:\n",
    "            path = self._get_dir_by_signal(signal)\n",
    "            file_path = self._get_last_saved_csv(path)\n",
    "            return pd.read_csv(file_path, index_col='Ticker')\n",
    "        except ValueError:\n",
    "            print('Could be there is no file for such index. '\n",
    "                  'Please run get_new_ath_df(save=True) function first.')\n",
    "            sys.tracebacklimit=0\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_dir_by_signal(signal):\n",
    "        if signal == 'ath':\n",
    "            return 'ATH_Data'\n",
    "        elif signal == 'ma':\n",
    "            return 'MA_Cross_Data'\n",
    "        elif signal == 'x-years':\n",
    "            return 'X-years_Max_Data'\n",
    "\n",
    "    def _get_last_saved_csv(self, path):\n",
    "        files = os.listdir(path)\n",
    "        files_paths = [os.path.join(path, basename) for basename in files]\n",
    "        return self._get_last_csv_path(files_paths)\n",
    "\n",
    "    def _get_last_csv_path(self, paths):\n",
    "        ''' Search for latest .csv file with appropriate file name (file_name_part) in the paths table.\n",
    "            Returns the last file path '''\n",
    "        last_file = max(paths, key=os.path.getctime)\n",
    "        if last_file[-4:] == '.csv' and self.__check_file_vs_index_name(last_file):\n",
    "            return last_file\n",
    "        else:\n",
    "            paths.remove(last_file)\n",
    "            return self._get_last_csv_path(paths)\n",
    "\n",
    "    def __check_file_vs_index_name(self, path):\n",
    "        index_name = path.split('_')[2:-1] # suits ATH_Data only\n",
    "        index_name = '_'.join(index_name)\n",
    "        return True if self.file_name_part == index_name else False\n",
    "\n",
    "    def _get_current_prices_dict(self):\n",
    "        yahoo_financials = YahooFinancials(self.tickers)\n",
    "        self.today_price_dict = yahoo_financials.get_current_price()\n",
    "        return self.today_price_dict\n",
    "\n",
    "    def save_updated_ath_df(self):\n",
    "        ''' Save new ATH data frame if get_comp_ath_list returned some ticker/s. '''\n",
    "        if self.new_ath:\n",
    "            today = datetime.today().strftime('%Y-%m-%d')\n",
    "            new_ath_df = self._update_ath_df_by_dict()\n",
    "            new_ath_df.to_csv(f'ATH_Data/ATH_{self.file_name_part}_{today}.csv')\n",
    "        else:\n",
    "            print('There is no need to save updated ATH csv because of none new ATH.')\n",
    "\n",
    "    def _update_ath_df_by_dict(self):\n",
    "        ''' Update ath data frame based on the new prices stored in dictionary.\n",
    "            Returns new data frame. '''\n",
    "        df = self._read_csv_data('ath')\n",
    "        mask = df.loc[self.today_price_dict.keys(), 'ATH'] < list(self.today_price_dict.values())\n",
    "        index_to_replace = list(mask[mask].index)\n",
    "        values_to_update = [self.today_price_dict[k] for k in index_to_replace]\n",
    "        df.loc[index_to_replace] = values_to_update\n",
    "        return df\n",
    "\n",
    "    def get_comp_x_years_max(self, years):\n",
    "        ''' Return the ticker/s name/s which beat its/theirs the x-years max/s.\n",
    "            The log file in X-years_Max_Data/ is automatically updated. '''\n",
    "        # to add the read/get tickers list?\n",
    "        start_date, end_date = self._get_start_end_date(years)\n",
    "        data = self._get_historical_data(start_date, end_date)\n",
    "        close_df = self._get_close_df(data)\n",
    "        max_ser = close_df.max()\n",
    "        if not self.today_price_dict:\n",
    "            self._get_current_prices_dict()\n",
    "        self.new_max = self._get_new_maxs(max_ser)\n",
    "        # check if x-years max log exist, if not create template\n",
    "        if not self.__check_if_file_exist(f'X-years_Max_Data/{self.file_name_part}_x_years_max.txt'):\n",
    "            self.__create_x_years_max_log_temp()\n",
    "        self._update_x_years_max_log_file(max_ser, years)\n",
    "        return self.new_max\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_start_end_date(years):\n",
    "        end = datetime.today() # - timedelta(days=1) <-- not needed because Yahoo already return [start, today-1] sessions\n",
    "        start = end - relativedelta(years=years)\n",
    "        return start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')\n",
    "\n",
    "    def _get_new_maxs(self, cur_max_ser):\n",
    "        ''' Returns tickers with new x-year maxes based on series with last maxima and new prices dictionary. '''\n",
    "        mask = cur_max_ser.loc[self.today_price_dict.keys()] < list(self.today_price_dict.values())\n",
    "        return list(cur_max_ser.loc[self.today_price_dict.keys()][mask].index)\n",
    "\n",
    "    @staticmethod\n",
    "    def __check_if_file_exist(path):\n",
    "        return os.path.isfile(path)\n",
    "    \n",
    "    def __create_x_years_max_log_temp(self):\n",
    "        with open(f'X-years_Max_Data/{self.file_name_part}_x_years_max.txt', 'a') as file:\n",
    "            file.write('Date, Ticker, Years, Old_max, New_max\\n')\n",
    "    \n",
    "    def _update_x_years_max_log_file(self, cur_max_ser, years):\n",
    "        ''' Update the log file with all new x-years maxima. '''\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        with open(f'X-years_Max_Data/{self.file_name_part}_x_years_max.txt', 'a') as file:\n",
    "            for ticker in self.new_max:\n",
    "                file.write(\n",
    "                    f'{today}, {ticker}, {years}, {self._round_2(cur_max_ser[ticker])}, {self._round_2(self.today_price_dict[ticker])}\\n')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _round_2(x):\n",
    "        return round(x, 2)\n",
    "\n",
    "    def get_ma_position_change(self, ma):\n",
    "        ''' Get (print) list of changed price positions relative to the MA value.\n",
    "            The file logs are saved after all actions.\n",
    "            That can be run only once per ma. Otherwise the outcome can by all equal positions.\n",
    "            None is returned. '''\n",
    "        if not self.today_price_dict:\n",
    "            self._get_current_prices_dict()\n",
    "        if not self.today_ma_dict or self.actual_ma != ma:  # actually self.actual_ma != ma should be enough\n",
    "            self.actual_ma = ma\n",
    "            self._get_moving_avg_dict(ma)\n",
    "        ma_pos_list = self._get_ma_position_list()\n",
    "        price_ma_df = self._create_ma_position_df(ma_pos_list)\n",
    "        last_price_ma_df = self._read_last_price_ma_pos_df(ma)\n",
    "        tickers_ser = self._get_ma_position_change_tickers(last_price_ma_df, price_ma_df)\n",
    "        self.__print_ma_positon_change(last_price_ma_df, price_ma_df, tickers_ser)\n",
    "        change_log_df = self._read_ma_pos_change_log(ma)\n",
    "        change_log_df = self._fill_in_ma_pos_change_log(change_log_df, last_price_ma_df, price_ma_df, tickers_ser)\n",
    "        self.__save_ma_log_and_last_price_ma_dfs(price_ma_df, change_log_df, ma)\n",
    "\n",
    "    def _get_moving_avg_dict(self, ma):\n",
    "        ''' Get today ma values. At the moment only ma 50 and 200 are supported by yahoo finance.\n",
    "            Returns a dictionary with tickers and ma values for each. '''\n",
    "        if not self.today_ma_dict:\n",
    "            yahoo_financials = YahooFinancials(self.tickers)\n",
    "            if ma == 50:\n",
    "                self.today_ma_dict = yahoo_financials.get_50day_moving_avg()\n",
    "            elif ma == 200:\n",
    "                self.today_ma_dict = yahoo_financials.get_200day_moving_avg()\n",
    "            else:\n",
    "                print(f'Wrong ma value {ma}. Only 50 and 200 are supported')\n",
    "        return self.today_ma_dict\n",
    "\n",
    "    def _get_ma_position_list(self, price_dict=None, ma_dict=None):\n",
    "        ''' By default the self.today_price_dict is used.\n",
    "            The self.today_ma_dict is fixed by _get_moving_avg_dict function.\n",
    "            Returns the list of price positions vs MA value. '''\n",
    "        if not price_dict:\n",
    "            price_dict = self.today_price_dict\n",
    "        if not ma_dict:\n",
    "            ma_dict = self.today_ma_dict\n",
    "        ma_position_list = []\n",
    "        for ticker, price in price_dict.items():\n",
    "            ma_value = ma_dict[ticker]\n",
    "            if price > ma_value:\n",
    "                ma_position_list.append('above')\n",
    "            elif price < ma_value:\n",
    "                ma_position_list.append('below')\n",
    "            else:\n",
    "                ma_position_list.append('equal')\n",
    "        return ma_position_list\n",
    "\n",
    "    def _create_ma_position_df(self, ma_position_list, price_dict=None):\n",
    "        ''' By default the self.today_price_dict is used.\n",
    "            The self.today_ma_dict is fixed by _get_moving_avg_dict function.\n",
    "            The ma_position_list needs to be provided.\n",
    "            Returns the data frame containing Ticker, Price, MA value and Position (Price vs MA) data. '''\n",
    "        if not price_dict:\n",
    "            price_dict = self.today_price_dict\n",
    "        price_ma_df = pd.DataFrame(columns=['Ticker', 'Price', 'MA', 'Position'])\n",
    "        price_ma_df['Ticker'] = price_dict.keys()\n",
    "        price_ma_df['Price'] = price_dict.values()\n",
    "        price_ma_df['MA'] = self.today_ma_dict.values()\n",
    "        price_ma_df['Position'] = ma_position_list\n",
    "        return price_ma_df\n",
    "\n",
    "    def _read_last_price_ma_pos_df(self, ma):\n",
    "        try:\n",
    "            return pd.read_csv(f'MA_Cross_Data/{self.file_name_part}_price_ma{ma}_position.csv')\n",
    "        except FileNotFoundError:\n",
    "            print('There is no csv file to load. Please run get_initial_price_ma_position function first.')\n",
    "            sys.tracebacklimit=0\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ma_position_change_tickers(last_price_ma_df, price_ma_df):\n",
    "        ''' Returns the series of tickers for which price vs ma value position changed. '''\n",
    "        mask = (last_price_ma_df['Position'] != price_ma_df['Position'])\n",
    "        tickers_ser = price_ma_df[mask]['Ticker']\n",
    "        #         self.__print_ma_positon_change(last_price_ma_df, price_ma_df, tickers_ser)\n",
    "        return tickers_ser\n",
    "\n",
    "    @staticmethod\n",
    "    def __print_ma_positon_change(last_price_ma_df, price_ma_df, tickers_ser):\n",
    "        ''' Print the information of price vs ma value position changes. '''\n",
    "        for i in tickers_ser.index:\n",
    "            if (last_price_ma_df.loc[i]['Position'] == 'above') & (price_ma_df.loc[i]['Position'] == 'below'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'LOST the MA')\n",
    "            elif (last_price_ma_df.loc[i]['Position'] == 'above') & (price_ma_df.loc[i]['Position'] == 'equal'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'DROPPED perfectly on the MA')\n",
    "            elif (last_price_ma_df.loc[i]['Position'] == 'below') & (price_ma_df.loc[i]['Position'] == 'above'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'BEAT the MA')\n",
    "            elif (last_price_ma_df.loc[i]['Position'] == 'below') & (price_ma_df.loc[i]['Position'] == 'equal'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'REACHED perfectly the MA')\n",
    "            elif (last_price_ma_df.loc[i]['Position'] == 'equal') & (price_ma_df.loc[i]['Position'] == 'above'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'BEAT (from prev. eq) the MA')\n",
    "            elif (last_price_ma_df.loc[i]['Position'] == 'equal') & (price_ma_df.loc[i]['Position'] == 'below'):\n",
    "                print(price_ma_df.loc[i]['Ticker'], 'LOST (from prev. eq) the MA')\n",
    "        if tickers_ser.empty:\n",
    "            print('It seems there is no changes. Is it weekend, holiday or market was so boring today?')\n",
    "\n",
    "    def _read_ma_pos_change_log(self, ma):\n",
    "        try:\n",
    "            return pd.read_csv(f'MA_Cross_Data/{self.file_name_part}_price_ma{ma}_change_log.csv', index_col='Index')\n",
    "        except FileNotFoundError:\n",
    "            print('There is no change log. Going to create and return blank one.')\n",
    "            return self._create_new_ma_change_log(ma)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_new_ma_change_log(ma):\n",
    "        df = pd.DataFrame(\n",
    "            columns=['Index', 'Date', 'Ticker', 'Prev. Price', 'Curr. Price', 'Prev. MA', 'Curr. MA', 'Prev. Position',\n",
    "                     'Curr. Position'])\n",
    "        df.set_index('Index', inplace=True)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _fill_in_ma_pos_change_log(change_log_df, last_price_ma_df, price_ma_df, tickers_ser):\n",
    "        ''' Goes through all tickers for which the price vs ma position changed and fill the change log.\n",
    "            Returns new change log data frame. '''\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        for idx in tickers_ser.index:\n",
    "            change_log_df.loc[len(change_log_df)] = [today, price_ma_df.loc[idx]['Ticker'],\n",
    "                                                     last_price_ma_df.loc[idx]['Price'], price_ma_df.loc[idx]['Price'],\n",
    "                                                     last_price_ma_df.loc[idx]['MA'], price_ma_df.loc[idx]['MA'],\n",
    "                                                     last_price_ma_df.loc[idx]['Position'],\n",
    "                                                     price_ma_df.loc[idx]['Position']]\n",
    "        return change_log_df\n",
    "\n",
    "    def __save_ma_log_and_last_price_ma_dfs(self, price_ma_df, change_log_df, ma):\n",
    "        self.__save_price_ma_df(price_ma_df, ma)\n",
    "        self.__save_change_log_df(change_log_df, ma)\n",
    "\n",
    "    def __save_change_log_df(self, change_log_df, ma):\n",
    "        change_log_df.to_csv(f'MA_Cross_Data/{self.file_name_part}_price_ma{ma}_change_log.csv')\n",
    "\n",
    "    def __save_price_ma_df(self, price_ma_df, ma):\n",
    "        price_ma_df.to_csv(f'MA_Cross_Data/{self.file_name_part}_price_ma{ma}_position.csv')\n",
    "\n",
    "    def get_initial_price_ma_position(self, ma):\n",
    "        ''' Get initial price vs ma value data frame.\n",
    "            The data for last session are fetched.\n",
    "            The ma value for last session is calculated from historical close prices.\n",
    "            The .csv file with price, ma and position is saved in MA_Cross_Data directory.\n",
    "            Returns the saved data frame. '''\n",
    "        start_date, end_date = self._get_last_session_day(), datetime.today().strftime('%Y-%m-%d')\n",
    "        last_session_price_data = self._get_historical_data(start_date, end_date)\n",
    "        last_session_price_dict = self._get_price_dict_from_hist_data(last_session_price_data)\n",
    "        # calculate ma value for last session\n",
    "        # 1.7*ma was chosen arbitrary to make sure we have ma sessions in the output\n",
    "        # 5 sessions of 7 days gives 1.4 but let's have some margin for holidays etc\n",
    "        start_date, end_date = (datetime.today() - timedelta(days=1.7*ma)).strftime('%Y-%m-%d'), datetime.today().strftime('%Y-%m-%d')\n",
    "        last_ma_prices_data = self._get_historical_data(start_date, end_date)\n",
    "        close_df = self._get_close_df(last_ma_prices_data)\n",
    "        ma_values_df = close_df.dropna().iloc[-ma:].mean()\n",
    "        ma_pos_list = self._get_ma_position_list(last_session_price_dict, dict(ma_values_df))\n",
    "        price_ma_df = self._create_ma_position_df(ma_pos_list, last_session_price_dict)\n",
    "        self.__save_price_ma_df(price_ma_df, ma)\n",
    "        return price_ma_df\n",
    "\n",
    "    def _get_last_session_day(self, curr_day=datetime.today()):\n",
    "        last = curr_day - timedelta(days=1)\n",
    "        # to skip weekend days\n",
    "        if last.weekday() > 4:\n",
    "            return self._get_last_session_day(last)\n",
    "        else:\n",
    "            return last.strftime('%Y-%m-%d')\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_price_dict_from_hist_data(data):\n",
    "        ''' Get the close prices from historical data (from yahoo).\n",
    "            Returns a dictionary with ticker as key and close price as value. '''\n",
    "        price_dict = {}\n",
    "        for ticker, hist_data in data.items():\n",
    "            close_price = hist_data['prices'][0]['close']\n",
    "            price_dict.update({ticker: close_price})\n",
    "        return price_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "organic-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALE.WA',\n",
       " 'ACP.WA',\n",
       " 'CCC.WA',\n",
       " 'CDR.WA',\n",
       " 'CPS.WA',\n",
       " 'DNP.WA',\n",
       " 'JSW.WA',\n",
       " 'KGH.WA',\n",
       " 'LTS.WA',\n",
       " 'LPP.WA',\n",
       " 'MBK.WA',\n",
       " 'OPL.WA',\n",
       " 'PEO.WA',\n",
       " 'PCO.WA',\n",
       " 'PGE.WA',\n",
       " 'PGN.WA',\n",
       " 'PKN.WA',\n",
       " 'PKO.WA',\n",
       " 'PZU.WA',\n",
       " 'SPL.WA']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_single = 'wig20'\n",
    "wig20_sf = SignalFinder(index_single)\n",
    "wig20_sf.get_tickers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "present-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_sf._check_components_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "developing-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wig20_sf.get_comp_ath_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "tamil-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 237\n",
      "ALE.WA       94.639999\n",
      "ACP.WA      176.765228\n",
      "CCC.WA      309.000000\n",
      "CDR.WA      460.799988\n",
      "CPS.WA       37.860001\n",
      "DNP.WA      374.799988\n",
      "JSW.WA      141.500000\n",
      "KGH.WA      223.800003\n",
      "LTS.WA       99.459999\n",
      "LPP.WA    18770.000000\n",
      "MBK.WA      600.000000\n",
      "OPL.WA       40.000000\n",
      "PEO.WA      271.700012\n",
      "PCO.WA       56.220001\n",
      "PGE.WA       25.700001\n",
      "PGN.WA        7.660000\n",
      "PKN.WA      134.000000\n",
      "PKO.WA       54.857697\n",
      "PZU.WA       51.099998\n",
      "SPL.WA      442.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALE.WA</th>\n",
       "      <td>94.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACP.WA</th>\n",
       "      <td>176.765228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCC.WA</th>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDR.WA</th>\n",
       "      <td>460.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPS.WA</th>\n",
       "      <td>37.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNP.WA</th>\n",
       "      <td>374.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSW.WA</th>\n",
       "      <td>141.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGH.WA</th>\n",
       "      <td>223.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTS.WA</th>\n",
       "      <td>99.459999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPP.WA</th>\n",
       "      <td>18770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBK.WA</th>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPL.WA</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEO.WA</th>\n",
       "      <td>271.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCO.WA</th>\n",
       "      <td>56.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGE.WA</th>\n",
       "      <td>25.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGN.WA</th>\n",
       "      <td>7.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKN.WA</th>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKO.WA</th>\n",
       "      <td>54.857697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PZU.WA</th>\n",
       "      <td>51.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPL.WA</th>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATH\n",
       "Ticker              \n",
       "ALE.WA     94.639999\n",
       "ACP.WA    176.765228\n",
       "CCC.WA    309.000000\n",
       "CDR.WA    460.799988\n",
       "CPS.WA     37.860001\n",
       "DNP.WA    374.799988\n",
       "JSW.WA    141.500000\n",
       "KGH.WA    223.800003\n",
       "LTS.WA     99.459999\n",
       "LPP.WA  18770.000000\n",
       "MBK.WA    600.000000\n",
       "OPL.WA     40.000000\n",
       "PEO.WA    271.700012\n",
       "PCO.WA     56.220001\n",
       "PGE.WA     25.700001\n",
       "PGN.WA      7.660000\n",
       "PKN.WA    134.000000\n",
       "PKO.WA     54.857697\n",
       "PZU.WA     51.099998\n",
       "SPL.WA    442.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_sf.get_new_ath_df(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "short-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wig20_sf.save_tickers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "universal-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_sf._check_components_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adaptive-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_sf.get_comp_x_years_max(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "every-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems there is no changes. Is it weekend, holiday or market was so boring today?\n"
     ]
    }
   ],
   "source": [
    "wig20_sf.get_ma_position_change(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sporting-novelty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>MA</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALE.WA</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.35250</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACP.WA</td>\n",
       "      <td>76.800003</td>\n",
       "      <td>77.28700</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCC.WA</td>\n",
       "      <td>47.590000</td>\n",
       "      <td>54.32420</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDR.WA</td>\n",
       "      <td>120.680000</td>\n",
       "      <td>154.04600</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPS.WA</td>\n",
       "      <td>22.280001</td>\n",
       "      <td>26.57760</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DNP.WA</td>\n",
       "      <td>301.700012</td>\n",
       "      <td>308.67800</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JSW.WA</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>69.76360</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KGH.WA</td>\n",
       "      <td>119.199997</td>\n",
       "      <td>161.16700</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LTS.WA</td>\n",
       "      <td>68.440002</td>\n",
       "      <td>63.17600</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LPP.WA</td>\n",
       "      <td>9850.000000</td>\n",
       "      <td>10037.10000</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MBK.WA</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>329.28400</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OPL.WA</td>\n",
       "      <td>6.322000</td>\n",
       "      <td>7.45258</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PEO.WA</td>\n",
       "      <td>88.459999</td>\n",
       "      <td>104.49580</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PCO.WA</td>\n",
       "      <td>40.759998</td>\n",
       "      <td>43.26890</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PGE.WA</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>9.35660</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PGN.WA</td>\n",
       "      <td>5.890000</td>\n",
       "      <td>6.46904</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PKN.WA</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>76.19880</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PKO.WA</td>\n",
       "      <td>30.450001</td>\n",
       "      <td>36.58000</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PZU.WA</td>\n",
       "      <td>29.940001</td>\n",
       "      <td>32.30200</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SPL.WA</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>281.96200</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker        Price           MA Position\n",
       "0   ALE.WA    23.000000     28.35250    below\n",
       "1   ACP.WA    76.800003     77.28700    below\n",
       "2   CCC.WA    47.590000     54.32420    below\n",
       "3   CDR.WA   120.680000    154.04600    below\n",
       "4   CPS.WA    22.280001     26.57760    below\n",
       "5   DNP.WA   301.700012    308.67800    below\n",
       "6   JSW.WA    68.000000     69.76360    below\n",
       "7   KGH.WA   119.199997    161.16700    below\n",
       "8   LTS.WA    68.440002     63.17600    above\n",
       "9   LPP.WA  9850.000000  10037.10000    below\n",
       "10  MBK.WA   273.000000    329.28400    below\n",
       "11  OPL.WA     6.322000      7.45258    below\n",
       "12  PEO.WA    88.459999    104.49580    below\n",
       "13  PCO.WA    40.759998     43.26890    below\n",
       "14  PGE.WA     9.482000      9.35660    above\n",
       "15  PGN.WA     5.890000      6.46904    below\n",
       "16  PKN.WA    73.500000     76.19880    below\n",
       "17  PKO.WA    30.450001     36.58000    below\n",
       "18  PZU.WA    29.940001     32.30200    below\n",
       "19  SPL.WA   244.000000    281.96200    below"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_sf.get_initial_price_ma_position(50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "differential-lending",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rough-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_all = 'wig20+mwig40+swig80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "private-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "wig20_40_80_sf = SignalFinder(index_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "federal-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALE.WA',\n",
       " 'ACP.WA',\n",
       " 'CCC.WA',\n",
       " 'CDR.WA',\n",
       " 'CPS.WA',\n",
       " 'DNP.WA',\n",
       " 'JSW.WA',\n",
       " 'KGH.WA',\n",
       " 'LTS.WA',\n",
       " 'LPP.WA',\n",
       " 'MBK.WA',\n",
       " 'OPL.WA',\n",
       " 'PEO.WA',\n",
       " 'PCO.WA',\n",
       " 'PGE.WA',\n",
       " 'PGN.WA',\n",
       " 'PKN.WA',\n",
       " 'PKO.WA',\n",
       " 'PZU.WA',\n",
       " 'SPL.WA',\n",
       " '11B.WA',\n",
       " 'ALR.WA',\n",
       " 'EAT.WA',\n",
       " 'ASB.WA',\n",
       " 'ASE.WA',\n",
       " 'BFT.WA',\n",
       " 'BML.WA',\n",
       " 'BDX.WA',\n",
       " 'CIE.WA',\n",
       " 'CLN.WA',\n",
       " 'CMR.WA',\n",
       " 'DAT.WA',\n",
       " 'DVL.WA',\n",
       " 'DOM.WA',\n",
       " 'ENA.WA',\n",
       " 'EUR.WA',\n",
       " 'FMF.WA',\n",
       " 'GPW.WA',\n",
       " 'ATT.WA',\n",
       " 'BHW.WA',\n",
       " 'HUG.WA',\n",
       " 'ING.WA',\n",
       " 'CAR.WA',\n",
       " 'KER.WA',\n",
       " 'KTY.WA',\n",
       " 'KRU.WA',\n",
       " 'LVC.WA',\n",
       " 'MAB.WA',\n",
       " 'MRC.WA',\n",
       " 'MIL.WA',\n",
       " 'MBR.WA',\n",
       " 'NEU.WA',\n",
       " 'PEP.WA',\n",
       " 'PKP.WA',\n",
       " 'PLW.WA',\n",
       " 'SLV.WA',\n",
       " 'TPE.WA',\n",
       " 'TEN.WA',\n",
       " 'WPL.WA',\n",
       " 'XTB.WA',\n",
       " 'ABE.WA',\n",
       " 'ACG.WA',\n",
       " 'ACT.WA',\n",
       " 'AGO.WA',\n",
       " 'AML.WA',\n",
       " 'AMB.WA',\n",
       " 'AMC.WA',\n",
       " 'ANR.WA',\n",
       " 'APT.WA',\n",
       " 'ATC.WA',\n",
       " 'ABS.WA',\n",
       " 'AST.WA',\n",
       " '1AT.WA',\n",
       " 'ATG.WA',\n",
       " 'APR.WA',\n",
       " 'BIO.WA',\n",
       " 'BNP.WA',\n",
       " 'LWB.WA',\n",
       " 'BRS.WA',\n",
       " 'BOS.WA',\n",
       " 'BOW.WA',\n",
       " 'BMC.WA',\n",
       " 'CTX.WA',\n",
       " 'CAV.WA',\n",
       " 'CIG.WA',\n",
       " 'CLE.WA',\n",
       " 'COG.WA',\n",
       " 'CMP.WA',\n",
       " 'CRJ.WA',\n",
       " 'DCR.WA',\n",
       " 'ECH.WA',\n",
       " 'ENT.WA',\n",
       " 'ERB.WA',\n",
       " 'FRO.WA',\n",
       " 'FTE.WA',\n",
       " 'GTN.WA',\n",
       " 'GNB.WA',\n",
       " 'GRN.WA',\n",
       " 'IMC.WA',\n",
       " 'INK.WA',\n",
       " 'KGN.WA',\n",
       " 'MCI.WA',\n",
       " 'MFO.WA',\n",
       " 'MRB.WA',\n",
       " 'MLS.WA',\n",
       " 'MOC.WA',\n",
       " 'NWG.WA',\n",
       " 'OND.WA',\n",
       " 'OPN.WA',\n",
       " 'PCR.WA',\n",
       " 'PCF.WA',\n",
       " 'PBX.WA',\n",
       " 'PHN.WA',\n",
       " 'PEN.WA',\n",
       " 'PCE.WA',\n",
       " 'PXM.WA',\n",
       " 'R22.WA',\n",
       " 'RFK.WA',\n",
       " 'RBW.WA',\n",
       " 'RWL.WA',\n",
       " 'RVU.WA',\n",
       " 'SNK.WA',\n",
       " 'SEN.WA',\n",
       " 'SHO.WA',\n",
       " 'SKA.WA',\n",
       " 'STX.WA',\n",
       " 'STP.WA',\n",
       " 'SNT.WA',\n",
       " 'TIM.WA',\n",
       " 'TOR.WA',\n",
       " 'TOA.WA',\n",
       " 'TRK.WA',\n",
       " 'UNT.WA',\n",
       " 'VRC.WA',\n",
       " 'VGO.WA',\n",
       " 'VOX.WA',\n",
       " 'VRG.WA',\n",
       " 'WWL.WA',\n",
       " 'WLT.WA',\n",
       " 'ZEP.WA']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_40_80_sf.get_tickers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polyphonic-action",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_40_80_sf._check_components_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mexican-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wig20_40_80_sf._read_csv_data('ath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "biblical-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH_Data\\ATH_wig20_mwig40_swig80_2022-04-28.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_40_80_sf.get_comp_ath_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "subtle-traffic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wig20_40_80_sf.get_comp_x_years_max(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "korean-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGE.WA BEAT the MA\n",
      "DAT.WA BEAT the MA\n",
      "ENA.WA BEAT the MA\n",
      "XTB.WA BEAT the MA\n",
      "ABE.WA BEAT the MA\n",
      "LWB.WA BEAT the MA\n",
      "GRN.WA BEAT the MA\n",
      "RFK.WA BEAT the MA\n",
      "VRG.WA LOST the MA\n",
      "WWL.WA BEAT the MA\n"
     ]
    }
   ],
   "source": [
    "wig20_40_80_sf.get_ma_position_change(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
